{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:27:37.594305Z",
     "iopub.status.busy": "2024-11-24T13:27:37.593927Z",
     "iopub.status.idle": "2024-11-24T13:27:53.984548Z",
     "shell.execute_reply": "2024-11-24T13:27:53.983459Z",
     "shell.execute_reply.started": "2024-11-24T13:27:37.594265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: torchgeometry in /opt/conda/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install torchgeometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-24T13:27:53.986134Z",
     "iopub.status.busy": "2024-11-24T13:27:53.985811Z",
     "iopub.status.idle": "2024-11-24T13:27:56.168854Z",
     "shell.execute_reply": "2024-11-24T13:27:56.168208Z",
     "shell.execute_reply.started": "2024-11-24T13:27:53.986097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchgeometry.losses import one_hot\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import Resize, PILToTensor, ToPILImage, Compose, InterpolationMode\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:27:56.170242Z",
     "iopub.status.busy": "2024-11-24T13:27:56.169978Z",
     "iopub.status.idle": "2024-11-24T13:27:56.203778Z",
     "shell.execute_reply": "2024-11-24T13:27:56.202719Z",
     "shell.execute_reply.started": "2024-11-24T13:27:56.170220Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:27:56.206265Z",
     "iopub.status.busy": "2024-11-24T13:27:56.205989Z",
     "iopub.status.idle": "2024-11-24T13:28:04.443613Z",
     "shell.execute_reply": "2024-11-24T13:28:04.442548Z",
     "shell.execute_reply.started": "2024-11-24T13:27:56.206242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation-models-pytorch in /opt/conda/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.26.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\n",
      "Requirement already satisfied: timm==0.9.7 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.7)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.0.9)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:04.445334Z",
     "iopub.status.busy": "2024-11-24T13:28:04.445072Z",
     "iopub.status.idle": "2024-11-24T13:28:06.700113Z",
     "shell.execute_reply": "2024-11-24T13:28:06.699399Z",
     "shell.execute_reply.started": "2024-11-24T13:28:04.445311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.701299Z",
     "iopub.status.busy": "2024-11-24T13:28:06.701050Z",
     "iopub.status.idle": "2024-11-24T13:28:06.705902Z",
     "shell.execute_reply": "2024-11-24T13:28:06.705053Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.701277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "epochs = 50\n",
    "learning_rate = 1e-03\n",
    "batch_size = 4\n",
    "display_step = 25\n",
    "\n",
    "#checkpoint_path = '/kaggle/working/unet_model.pth'\n",
    "checkpoint_path = '/model/unet.pth'\n",
    "\n",
    "loss_epoch_array = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "valid_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.707195Z",
     "iopub.status.busy": "2024-11-24T13:28:06.706960Z",
     "iopub.status.idle": "2024-11-24T13:28:06.720404Z",
     "shell.execute_reply": "2024-11-24T13:28:06.719706Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.707175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = Compose([Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n",
    "                     PILToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.721608Z",
     "iopub.status.busy": "2024-11-24T13:28:06.721382Z",
     "iopub.status.idle": "2024-11-24T13:28:06.730856Z",
     "shell.execute_reply": "2024-11-24T13:28:06.730064Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.721589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNetDataClass(Dataset):\n",
    "    def __init__(self, images_path, masks_path, transform):\n",
    "        super(UNetDataClass, self).__init__()\n",
    "        \n",
    "        images_list = os.listdir(images_path)\n",
    "        masks_list = os.listdir(masks_path)\n",
    "        \n",
    "        images_list = [images_path + image_name for image_name in images_list]\n",
    "        masks_list = [masks_path + mask_name for mask_name in masks_list]\n",
    "        \n",
    "        self.images_list = images_list\n",
    "        self.masks_list = masks_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        mask_path = self.masks_list[index]\n",
    "        \n",
    "        # Open image and mask\n",
    "        data = Image.open(img_path)\n",
    "        label = Image.open(mask_path)\n",
    "        \n",
    "        # Normalize\n",
    "        data = self.transform(data) / 255\n",
    "        label = self.transform(label) / 255\n",
    "        \n",
    "        label = torch.where(label>0.65, 1.0, 0.0)\n",
    "        \n",
    "        label[2, :, :] = 0.0001\n",
    "        label = torch.argmax(label, 0).type(torch.int64)\n",
    "        \n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.731975Z",
     "iopub.status.busy": "2024-11-24T13:28:06.731747Z",
     "iopub.status.idle": "2024-11-24T13:28:06.743005Z",
     "shell.execute_reply": "2024-11-24T13:28:06.742272Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.731955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n",
    "#masks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"\n",
    "images_path = \"/train/train/\"\n",
    "masks_path =  \"/train_gt/train_gt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.744073Z",
     "iopub.status.busy": "2024-11-24T13:28:06.743868Z",
     "iopub.status.idle": "2024-11-24T13:28:06.756836Z",
     "shell.execute_reply": "2024-11-24T13:28:06.756196Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.744055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unet_dataset = UNetDataClass(images_path, masks_path, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.757944Z",
     "iopub.status.busy": "2024-11-24T13:28:06.757739Z",
     "iopub.status.idle": "2024-11-24T13:28:06.763862Z",
     "shell.execute_reply": "2024-11-24T13:28:06.763139Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.757926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = 0.9\n",
    "valid_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.765039Z",
     "iopub.status.busy": "2024-11-24T13:28:06.764807Z",
     "iopub.status.idle": "2024-11-24T13:28:06.773912Z",
     "shell.execute_reply": "2024-11-24T13:28:06.773196Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.765020Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_set, valid_set = random_split(unet_dataset, \n",
    "                                    [int(train_size * len(unet_dataset)) , \n",
    "                                     int(valid_size * len(unet_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:06.777397Z",
     "iopub.status.busy": "2024-11-24T13:28:06.777160Z",
     "iopub.status.idle": "2024-11-24T13:28:06.788025Z",
     "shell.execute_reply": "2024-11-24T13:28:06.787322Z",
     "shell.execute_reply.started": "2024-11-24T13:28:06.777377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.353589Z",
     "iopub.status.busy": "2024-11-24T13:28:07.352803Z",
     "iopub.status.idle": "2024-11-24T13:28:07.358423Z",
     "shell.execute_reply": "2024-11-24T13:28:07.357566Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.353554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,\n",
    "    RandomGamma,\n",
    "    RGBShift,\n",
    ")\n",
    "\n",
    "augmentation = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    VerticalFlip(p=0.5),\n",
    "    RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n",
    "    RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.359603Z",
     "iopub.status.busy": "2024-11-24T13:28:07.359401Z",
     "iopub.status.idle": "2024-11-24T13:28:07.373909Z",
     "shell.execute_reply": "2024-11-24T13:28:07.373182Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.359585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SegDataClass(Dataset):\n",
    "    def __init__(self, images_path, masks_path, transform=None, augmentation=None):\n",
    "        super(SegDataClass, self).__init__()\n",
    "        \n",
    "        images_list = os.listdir(images_path)\n",
    "        masks_list = os.listdir(masks_path)\n",
    "        \n",
    "        images_list = [os.path.join(images_path, image_name) for image_name in images_list]\n",
    "        masks_list = [os.path.join(masks_path, mask_name) for mask_name in masks_list]\n",
    "        \n",
    "        self.images_list = images_list\n",
    "        self.masks_list = masks_list\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        mask_path = self.masks_list[index]\n",
    "        \n",
    "        data = Image.open(img_path)\n",
    "        label = Image.open(mask_path)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            augmented = self.augmentation(image=np.array(data), mask=np.array(label))\n",
    "            data = Image.fromarray(augmented['image'])\n",
    "            label = Image.fromarray(augmented['mask'])\n",
    "        \n",
    "        data = self.transform(data) / 255\n",
    "        label = self.transform(label) / 255\n",
    "        \n",
    "        label = torch.where(label > 0.65, 1.0, 0.0)\n",
    "        label[2, :, :] = 0.0001\n",
    "        label = torch.argmax(label, 0).type(torch.int64)\n",
    "        \n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "aug_dataset = SegDataClass(images_path, masks_path, transform=transform, augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.375263Z",
     "iopub.status.busy": "2024-11-24T13:28:07.374962Z",
     "iopub.status.idle": "2024-11-24T13:28:07.382035Z",
     "shell.execute_reply": "2024-11-24T13:28:07.381424Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.375234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_aug_set, valid_aug_set = random_split(aug_dataset, \n",
    "                                    [int(train_size * len(aug_dataset)) , \n",
    "                                     int(valid_size * len(aug_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.383376Z",
     "iopub.status.busy": "2024-11-24T13:28:07.383076Z",
     "iopub.status.idle": "2024-11-24T13:28:07.391265Z",
     "shell.execute_reply": "2024-11-24T13:28:07.390587Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.383347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_aug_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.393128Z",
     "iopub.status.busy": "2024-11-24T13:28:07.392292Z",
     "iopub.status.idle": "2024-11-24T13:28:07.405955Z",
     "shell.execute_reply": "2024-11-24T13:28:07.405121Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.393098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CEDiceLoss(nn.Module):\n",
    "    def __init__(self, weights) -> None:\n",
    "        super(CEDiceLoss, self).__init__()\n",
    "        self.eps: float = 1e-6\n",
    "        self.weights: torch.Tensor = weights\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input: torch.Tensor,\n",
    "            target: torch.Tensor) -> torch.Tensor:\n",
    "        if not torch.is_tensor(input):\n",
    "            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                            .format(type(input)))\n",
    "        if not len(input.shape) == 4:\n",
    "            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n",
    "                             .format(input.shape))\n",
    "        if not input.shape[-2:] == target.shape[-2:]:\n",
    "            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n",
    "                             .format(input.shape, input.shape))\n",
    "        if not input.device == target.device:\n",
    "            raise ValueError(\n",
    "                \"input and target must be in the same device. Got: {}\" .format(\n",
    "                    input.device, target.device))\n",
    "        if not self.weights.shape[1] == input.shape[1]:\n",
    "            raise ValueError(\"The number of weights must equal the number of classes\")\n",
    "        if not torch.sum(self.weights).item() == 1:\n",
    "            raise ValueError(\"The sum of all weights must equal 1\")\n",
    "            \n",
    "        # cross entropy loss\n",
    "        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n",
    "        \n",
    "        # compute softmax over the classes axis\n",
    "        input_soft = F.softmax(input, dim=1)\n",
    "\n",
    "        # create the labels one hot tensor\n",
    "        target_one_hot = one_hot(target, num_classes=input.shape[1],\n",
    "                                 device=input.device, dtype=input.dtype)\n",
    "\n",
    "        # compute the actual dice score\n",
    "        dims = (2, 3)\n",
    "        intersection = torch.sum(input_soft * target_one_hot, dims)\n",
    "        cardinality = torch.sum(input_soft + target_one_hot, dims)\n",
    "\n",
    "        dice_score = 2. * intersection / (cardinality + self.eps)\n",
    "        \n",
    "        dice_score = torch.sum(dice_score * self.weights, dim=1)\n",
    "        \n",
    "        return torch.mean(1. - dice_score) + celoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.407439Z",
     "iopub.status.busy": "2024-11-24T13:28:07.407112Z",
     "iopub.status.idle": "2024-11-24T13:28:07.420846Z",
     "shell.execute_reply": "2024-11-24T13:28:07.420112Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.407410Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    if isinstance(model, nn.Linear):\n",
    "        # Xavier Distribution\n",
    "        torch.nn.init.xavier_uniform_(model.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\n",
    "loss_function = CEDiceLoss(weights)\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler\n",
    "#learing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)\n",
    "learing_rate_scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "#learing_rate_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.422004Z",
     "iopub.status.busy": "2024-11-24T13:28:07.421766Z",
     "iopub.status.idle": "2024-11-24T13:28:07.433863Z",
     "shell.execute_reply": "2024-11-24T13:28:07.433170Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.421985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train function for each epoch\n",
    "def train(train_dataloader, valid_dataloader,learing_rate_scheduler, epoch, display_step):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {lr}\")\n",
    "    start_time = time.time()\n",
    "    train_loss_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    last_loss = 999999999\n",
    "    model.train()\n",
    "    for i, (data,targets) in enumerate(train_dataloader):\n",
    "        \n",
    "        # Load data into GPU\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        # Backpropagation, compute gradients\n",
    "        loss = loss_function(outputs, targets.long())\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Save loss\n",
    "        train_loss_epoch += loss.item()\n",
    "        if (i+1) % display_step == 0:\n",
    "#             accuracy = float(test(test_loader))\n",
    "            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}'.format(\n",
    "                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), \n",
    "                loss.item()))\n",
    "                  \n",
    "    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n",
    "    train_loss_epoch/= (i + 1)\n",
    "    \n",
    "    # Evaluate the validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            test_output = model(data)\n",
    "            test_loss = loss_function(test_output, target)\n",
    "            test_loss_epoch += test_loss.item()\n",
    "            \n",
    "    test_loss_epoch/= (i+1)\n",
    "    \n",
    "    return train_loss_epoch , test_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.435507Z",
     "iopub.status.busy": "2024-11-24T13:28:07.434955Z",
     "iopub.status.idle": "2024-11-24T13:28:07.450693Z",
     "shell.execute_reply": "2024-11-24T13:28:07.449916Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.435476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, targets) in enumerate(dataloader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            test_loss += targets.size(0)\n",
    "            correct += torch.sum(pred == targets).item()\n",
    "    return 100.0 * correct / test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:07.451855Z",
     "iopub.status.busy": "2024-11-24T13:28:07.451576Z",
     "iopub.status.idle": "2024-11-24T13:28:07.612221Z",
     "shell.execute_reply": "2024-11-24T13:28:07.611525Z",
     "shell.execute_reply.started": "2024-11-24T13:28:07.451834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.apply(weights_init)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(\n",
    "    key = \"key_here\",\n",
    ")\n",
    "wandb.init(\n",
    "    project=\"bkai-polyp\",\n",
    "    name=\"exponential_lr2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T13:28:37.715330Z",
     "iopub.status.busy": "2024-11-24T13:28:37.715023Z",
     "iopub.status.idle": "2024-11-24T14:24:58.558765Z",
     "shell.execute_reply": "2024-11-24T14:24:58.557735Z",
     "shell.execute_reply.started": "2024-11-24T13:28:37.715299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch #1, learning rate for this epoch: 0.001\n",
      "Train Epoch: 1 [100/900 (11.11111111111111%)]\tLoss: 1.2312\n",
      "Train Epoch: 1 [200/900 (22.22222222222222%)]\tLoss: 1.4080\n",
      "Train Epoch: 1 [300/900 (33.333333333333336%)]\tLoss: 1.1388\n",
      "Train Epoch: 1 [400/900 (44.44444444444444%)]\tLoss: 1.0587\n",
      "Train Epoch: 1 [500/900 (55.55555555555556%)]\tLoss: 1.1722\n",
      "Train Epoch: 1 [600/900 (66.66666666666667%)]\tLoss: 1.2157\n",
      "Train Epoch: 1 [700/900 (77.77777777777777%)]\tLoss: 1.1907\n",
      "Train Epoch: 1 [800/900 (88.88888888888889%)]\tLoss: 1.0988\n",
      "Train Epoch: 1 [900/900 (100.0%)]\tLoss: 1.5023\n",
      "Done epoch #1, time for this epoch: 65.09183645248413s\n",
      "Start epoch #2, learning rate for this epoch: 0.00095\n",
      "Train Epoch: 2 [100/900 (11.11111111111111%)]\tLoss: 1.1014\n",
      "Train Epoch: 2 [200/900 (22.22222222222222%)]\tLoss: 0.9473\n",
      "Train Epoch: 2 [300/900 (33.333333333333336%)]\tLoss: 1.1420\n",
      "Train Epoch: 2 [400/900 (44.44444444444444%)]\tLoss: 1.2612\n",
      "Train Epoch: 2 [500/900 (55.55555555555556%)]\tLoss: 1.2555\n",
      "Train Epoch: 2 [600/900 (66.66666666666667%)]\tLoss: 0.9641\n",
      "Train Epoch: 2 [700/900 (77.77777777777777%)]\tLoss: 1.5362\n",
      "Train Epoch: 2 [800/900 (88.88888888888889%)]\tLoss: 1.9065\n",
      "Train Epoch: 2 [900/900 (100.0%)]\tLoss: 0.8794\n",
      "Done epoch #2, time for this epoch: 63.69564414024353s\n",
      "Start epoch #3, learning rate for this epoch: 0.0009025\n",
      "Train Epoch: 3 [100/900 (11.11111111111111%)]\tLoss: 1.2022\n",
      "Train Epoch: 3 [200/900 (22.22222222222222%)]\tLoss: 1.5473\n",
      "Train Epoch: 3 [300/900 (33.333333333333336%)]\tLoss: 0.9135\n",
      "Train Epoch: 3 [400/900 (44.44444444444444%)]\tLoss: 0.9694\n",
      "Train Epoch: 3 [500/900 (55.55555555555556%)]\tLoss: 1.1173\n",
      "Train Epoch: 3 [600/900 (66.66666666666667%)]\tLoss: 0.7838\n",
      "Train Epoch: 3 [700/900 (77.77777777777777%)]\tLoss: 0.9262\n",
      "Train Epoch: 3 [800/900 (88.88888888888889%)]\tLoss: 1.0785\n",
      "Train Epoch: 3 [900/900 (100.0%)]\tLoss: 1.1281\n",
      "Done epoch #3, time for this epoch: 64.44114446640015s\n",
      "Start epoch #4, learning rate for this epoch: 0.000857375\n",
      "Train Epoch: 4 [100/900 (11.11111111111111%)]\tLoss: 0.9677\n",
      "Train Epoch: 4 [200/900 (22.22222222222222%)]\tLoss: 1.3159\n",
      "Train Epoch: 4 [300/900 (33.333333333333336%)]\tLoss: 0.8896\n",
      "Train Epoch: 4 [400/900 (44.44444444444444%)]\tLoss: 1.8215\n",
      "Train Epoch: 4 [500/900 (55.55555555555556%)]\tLoss: 1.0753\n",
      "Train Epoch: 4 [600/900 (66.66666666666667%)]\tLoss: 0.9653\n",
      "Train Epoch: 4 [700/900 (77.77777777777777%)]\tLoss: 0.9391\n",
      "Train Epoch: 4 [800/900 (88.88888888888889%)]\tLoss: 0.9545\n",
      "Train Epoch: 4 [900/900 (100.0%)]\tLoss: 1.4224\n",
      "Done epoch #4, time for this epoch: 62.88212180137634s\n",
      "Start epoch #5, learning rate for this epoch: 0.0008145062499999999\n",
      "Train Epoch: 5 [100/900 (11.11111111111111%)]\tLoss: 1.2101\n",
      "Train Epoch: 5 [200/900 (22.22222222222222%)]\tLoss: 0.8544\n",
      "Train Epoch: 5 [300/900 (33.333333333333336%)]\tLoss: 2.9237\n",
      "Train Epoch: 5 [400/900 (44.44444444444444%)]\tLoss: 1.3644\n",
      "Train Epoch: 5 [500/900 (55.55555555555556%)]\tLoss: 1.2649\n",
      "Train Epoch: 5 [600/900 (66.66666666666667%)]\tLoss: 0.9344\n",
      "Train Epoch: 5 [700/900 (77.77777777777777%)]\tLoss: 0.9735\n",
      "Train Epoch: 5 [800/900 (88.88888888888889%)]\tLoss: 1.2071\n",
      "Train Epoch: 5 [900/900 (100.0%)]\tLoss: 0.9944\n",
      "Done epoch #5, time for this epoch: 64.36283874511719s\n",
      "Start epoch #6, learning rate for this epoch: 0.0007737809374999998\n",
      "Train Epoch: 6 [100/900 (11.11111111111111%)]\tLoss: 1.0183\n",
      "Train Epoch: 6 [200/900 (22.22222222222222%)]\tLoss: 0.9089\n",
      "Train Epoch: 6 [300/900 (33.333333333333336%)]\tLoss: 0.7171\n",
      "Train Epoch: 6 [400/900 (44.44444444444444%)]\tLoss: 0.7885\n",
      "Train Epoch: 6 [500/900 (55.55555555555556%)]\tLoss: 0.9036\n",
      "Train Epoch: 6 [600/900 (66.66666666666667%)]\tLoss: 1.1078\n",
      "Train Epoch: 6 [700/900 (77.77777777777777%)]\tLoss: 0.9245\n",
      "Train Epoch: 6 [800/900 (88.88888888888889%)]\tLoss: 1.1914\n",
      "Train Epoch: 6 [900/900 (100.0%)]\tLoss: 1.4679\n",
      "Done epoch #6, time for this epoch: 64.10159587860107s\n",
      "Start epoch #7, learning rate for this epoch: 0.0007350918906249997\n",
      "Train Epoch: 7 [100/900 (11.11111111111111%)]\tLoss: 0.8873\n",
      "Train Epoch: 7 [200/900 (22.22222222222222%)]\tLoss: 1.0006\n",
      "Train Epoch: 7 [300/900 (33.333333333333336%)]\tLoss: 0.9073\n",
      "Train Epoch: 7 [400/900 (44.44444444444444%)]\tLoss: 0.8339\n",
      "Train Epoch: 7 [500/900 (55.55555555555556%)]\tLoss: 0.8432\n",
      "Train Epoch: 7 [600/900 (66.66666666666667%)]\tLoss: 0.8309\n",
      "Train Epoch: 7 [700/900 (77.77777777777777%)]\tLoss: 0.8824\n",
      "Train Epoch: 7 [800/900 (88.88888888888889%)]\tLoss: 0.8150\n",
      "Train Epoch: 7 [900/900 (100.0%)]\tLoss: 0.8999\n",
      "Done epoch #7, time for this epoch: 49.359726667404175s\n",
      "Start epoch #8, learning rate for this epoch: 0.0006983372960937497\n",
      "Train Epoch: 8 [100/900 (11.11111111111111%)]\tLoss: 3.1637\n",
      "Train Epoch: 8 [200/900 (22.22222222222222%)]\tLoss: 0.9590\n",
      "Train Epoch: 8 [300/900 (33.333333333333336%)]\tLoss: 0.8804\n",
      "Train Epoch: 8 [400/900 (44.44444444444444%)]\tLoss: 0.7372\n",
      "Train Epoch: 8 [500/900 (55.55555555555556%)]\tLoss: 1.0778\n",
      "Train Epoch: 8 [600/900 (66.66666666666667%)]\tLoss: 0.6980\n",
      "Train Epoch: 8 [700/900 (77.77777777777777%)]\tLoss: 0.8414\n",
      "Train Epoch: 8 [800/900 (88.88888888888889%)]\tLoss: 0.8876\n",
      "Train Epoch: 8 [900/900 (100.0%)]\tLoss: 0.9416\n",
      "Done epoch #8, time for this epoch: 49.27614879608154s\n",
      "Start epoch #9, learning rate for this epoch: 0.0006634204312890621\n",
      "Train Epoch: 9 [100/900 (11.11111111111111%)]\tLoss: 0.9447\n",
      "Train Epoch: 9 [200/900 (22.22222222222222%)]\tLoss: 0.8209\n",
      "Train Epoch: 9 [300/900 (33.333333333333336%)]\tLoss: 0.7228\n",
      "Train Epoch: 9 [400/900 (44.44444444444444%)]\tLoss: 0.9209\n",
      "Train Epoch: 9 [500/900 (55.55555555555556%)]\tLoss: 0.7361\n",
      "Train Epoch: 9 [600/900 (66.66666666666667%)]\tLoss: 1.0246\n",
      "Train Epoch: 9 [700/900 (77.77777777777777%)]\tLoss: 1.0419\n",
      "Train Epoch: 9 [800/900 (88.88888888888889%)]\tLoss: 0.7603\n",
      "Train Epoch: 9 [900/900 (100.0%)]\tLoss: 1.0571\n",
      "Done epoch #9, time for this epoch: 64.05672597885132s\n",
      "Start epoch #10, learning rate for this epoch: 0.000630249409724609\n",
      "Train Epoch: 10 [100/900 (11.11111111111111%)]\tLoss: 1.3143\n",
      "Train Epoch: 10 [200/900 (22.22222222222222%)]\tLoss: 1.2148\n",
      "Train Epoch: 10 [300/900 (33.333333333333336%)]\tLoss: 0.7574\n",
      "Train Epoch: 10 [400/900 (44.44444444444444%)]\tLoss: 0.8925\n",
      "Train Epoch: 10 [500/900 (55.55555555555556%)]\tLoss: 0.7622\n",
      "Train Epoch: 10 [600/900 (66.66666666666667%)]\tLoss: 0.7354\n",
      "Train Epoch: 10 [700/900 (77.77777777777777%)]\tLoss: 0.8242\n",
      "Train Epoch: 10 [800/900 (88.88888888888889%)]\tLoss: 0.7301\n",
      "Train Epoch: 10 [900/900 (100.0%)]\tLoss: 0.9063\n",
      "Done epoch #10, time for this epoch: 64.06888175010681s\n",
      "Start epoch #11, learning rate for this epoch: 0.0005987369392383785\n",
      "Train Epoch: 11 [100/900 (11.11111111111111%)]\tLoss: 0.6663\n",
      "Train Epoch: 11 [200/900 (22.22222222222222%)]\tLoss: 1.0220\n",
      "Train Epoch: 11 [300/900 (33.333333333333336%)]\tLoss: 1.2440\n",
      "Train Epoch: 11 [400/900 (44.44444444444444%)]\tLoss: 1.2062\n",
      "Train Epoch: 11 [500/900 (55.55555555555556%)]\tLoss: 0.8717\n",
      "Train Epoch: 11 [600/900 (66.66666666666667%)]\tLoss: 0.7618\n",
      "Train Epoch: 11 [700/900 (77.77777777777777%)]\tLoss: 0.9235\n",
      "Train Epoch: 11 [800/900 (88.88888888888889%)]\tLoss: 0.9618\n",
      "Train Epoch: 11 [900/900 (100.0%)]\tLoss: 1.0212\n",
      "Done epoch #11, time for this epoch: 63.999335050582886s\n",
      "Start epoch #12, learning rate for this epoch: 0.0005688000922764595\n",
      "Train Epoch: 12 [100/900 (11.11111111111111%)]\tLoss: 0.8607\n",
      "Train Epoch: 12 [200/900 (22.22222222222222%)]\tLoss: 0.8307\n",
      "Train Epoch: 12 [300/900 (33.333333333333336%)]\tLoss: 0.9034\n",
      "Train Epoch: 12 [400/900 (44.44444444444444%)]\tLoss: 0.7927\n",
      "Train Epoch: 12 [500/900 (55.55555555555556%)]\tLoss: 0.7890\n",
      "Train Epoch: 12 [600/900 (66.66666666666667%)]\tLoss: 0.8017\n",
      "Train Epoch: 12 [700/900 (77.77777777777777%)]\tLoss: 0.6932\n",
      "Train Epoch: 12 [800/900 (88.88888888888889%)]\tLoss: 0.7516\n",
      "Train Epoch: 12 [900/900 (100.0%)]\tLoss: 0.7980\n",
      "Done epoch #12, time for this epoch: 63.48439121246338s\n",
      "Start epoch #13, learning rate for this epoch: 0.0005403600876626365\n",
      "Train Epoch: 13 [100/900 (11.11111111111111%)]\tLoss: 0.9367\n",
      "Train Epoch: 13 [200/900 (22.22222222222222%)]\tLoss: 0.6861\n",
      "Train Epoch: 13 [300/900 (33.333333333333336%)]\tLoss: 0.7343\n",
      "Train Epoch: 13 [400/900 (44.44444444444444%)]\tLoss: 0.9624\n",
      "Train Epoch: 13 [500/900 (55.55555555555556%)]\tLoss: 0.8029\n",
      "Train Epoch: 13 [600/900 (66.66666666666667%)]\tLoss: 0.8126\n",
      "Train Epoch: 13 [700/900 (77.77777777777777%)]\tLoss: 0.8978\n",
      "Train Epoch: 13 [800/900 (88.88888888888889%)]\tLoss: 0.7953\n",
      "Train Epoch: 13 [900/900 (100.0%)]\tLoss: 0.6215\n",
      "Done epoch #13, time for this epoch: 64.37219095230103s\n",
      "Start epoch #14, learning rate for this epoch: 0.0005133420832795047\n",
      "Train Epoch: 14 [100/900 (11.11111111111111%)]\tLoss: 0.9371\n",
      "Train Epoch: 14 [200/900 (22.22222222222222%)]\tLoss: 0.9079\n",
      "Train Epoch: 14 [300/900 (33.333333333333336%)]\tLoss: 0.7217\n",
      "Train Epoch: 14 [400/900 (44.44444444444444%)]\tLoss: 0.6903\n",
      "Train Epoch: 14 [500/900 (55.55555555555556%)]\tLoss: 1.1118\n",
      "Train Epoch: 14 [600/900 (66.66666666666667%)]\tLoss: 0.7253\n",
      "Train Epoch: 14 [700/900 (77.77777777777777%)]\tLoss: 0.8788\n",
      "Train Epoch: 14 [800/900 (88.88888888888889%)]\tLoss: 0.6023\n",
      "Train Epoch: 14 [900/900 (100.0%)]\tLoss: 0.6865\n",
      "Done epoch #14, time for this epoch: 64.61521005630493s\n",
      "Start epoch #15, learning rate for this epoch: 0.00048767497911552944\n",
      "Train Epoch: 15 [100/900 (11.11111111111111%)]\tLoss: 0.7287\n",
      "Train Epoch: 15 [200/900 (22.22222222222222%)]\tLoss: 0.6544\n",
      "Train Epoch: 15 [300/900 (33.333333333333336%)]\tLoss: 0.6372\n",
      "Train Epoch: 15 [400/900 (44.44444444444444%)]\tLoss: 0.6504\n",
      "Train Epoch: 15 [500/900 (55.55555555555556%)]\tLoss: 0.6579\n",
      "Train Epoch: 15 [600/900 (66.66666666666667%)]\tLoss: 0.8172\n",
      "Train Epoch: 15 [700/900 (77.77777777777777%)]\tLoss: 0.6127\n",
      "Train Epoch: 15 [800/900 (88.88888888888889%)]\tLoss: 0.7332\n",
      "Train Epoch: 15 [900/900 (100.0%)]\tLoss: 0.7474\n",
      "Done epoch #15, time for this epoch: 64.21213459968567s\n",
      "Start epoch #16, learning rate for this epoch: 0.00046329123015975297\n",
      "Train Epoch: 16 [100/900 (11.11111111111111%)]\tLoss: 0.7470\n",
      "Train Epoch: 16 [200/900 (22.22222222222222%)]\tLoss: 0.7445\n",
      "Train Epoch: 16 [300/900 (33.333333333333336%)]\tLoss: 0.7913\n",
      "Train Epoch: 16 [400/900 (44.44444444444444%)]\tLoss: 0.7599\n",
      "Train Epoch: 16 [500/900 (55.55555555555556%)]\tLoss: 0.9142\n",
      "Train Epoch: 16 [600/900 (66.66666666666667%)]\tLoss: 0.7520\n",
      "Train Epoch: 16 [700/900 (77.77777777777777%)]\tLoss: 0.7404\n",
      "Train Epoch: 16 [800/900 (88.88888888888889%)]\tLoss: 0.6252\n",
      "Train Epoch: 16 [900/900 (100.0%)]\tLoss: 0.8202\n",
      "Done epoch #16, time for this epoch: 63.64585876464844s\n",
      "Start epoch #17, learning rate for this epoch: 0.0004401266686517653\n",
      "Train Epoch: 17 [100/900 (11.11111111111111%)]\tLoss: 0.6079\n",
      "Train Epoch: 17 [200/900 (22.22222222222222%)]\tLoss: 0.7483\n",
      "Train Epoch: 17 [300/900 (33.333333333333336%)]\tLoss: 0.5875\n",
      "Train Epoch: 17 [400/900 (44.44444444444444%)]\tLoss: 0.8191\n",
      "Train Epoch: 17 [500/900 (55.55555555555556%)]\tLoss: 0.6244\n",
      "Train Epoch: 17 [600/900 (66.66666666666667%)]\tLoss: 0.7511\n",
      "Train Epoch: 17 [700/900 (77.77777777777777%)]\tLoss: 0.8116\n",
      "Train Epoch: 17 [800/900 (88.88888888888889%)]\tLoss: 0.9448\n",
      "Train Epoch: 17 [900/900 (100.0%)]\tLoss: 0.6333\n",
      "Done epoch #17, time for this epoch: 64.1155788898468s\n",
      "Start epoch #18, learning rate for this epoch: 0.00041812033521917703\n",
      "Train Epoch: 18 [100/900 (11.11111111111111%)]\tLoss: 0.7607\n",
      "Train Epoch: 18 [200/900 (22.22222222222222%)]\tLoss: 0.5824\n",
      "Train Epoch: 18 [300/900 (33.333333333333336%)]\tLoss: 0.6899\n",
      "Train Epoch: 18 [400/900 (44.44444444444444%)]\tLoss: 0.7801\n",
      "Train Epoch: 18 [500/900 (55.55555555555556%)]\tLoss: 0.7756\n",
      "Train Epoch: 18 [600/900 (66.66666666666667%)]\tLoss: 0.5536\n",
      "Train Epoch: 18 [700/900 (77.77777777777777%)]\tLoss: 0.6198\n",
      "Train Epoch: 18 [800/900 (88.88888888888889%)]\tLoss: 0.9422\n",
      "Train Epoch: 18 [900/900 (100.0%)]\tLoss: 0.7607\n",
      "Done epoch #18, time for this epoch: 63.98314428329468s\n",
      "Start epoch #19, learning rate for this epoch: 0.00039721431845821814\n",
      "Train Epoch: 19 [100/900 (11.11111111111111%)]\tLoss: 0.8009\n",
      "Train Epoch: 19 [200/900 (22.22222222222222%)]\tLoss: 0.6184\n",
      "Train Epoch: 19 [300/900 (33.333333333333336%)]\tLoss: 0.6044\n",
      "Train Epoch: 19 [400/900 (44.44444444444444%)]\tLoss: 0.7245\n",
      "Train Epoch: 19 [500/900 (55.55555555555556%)]\tLoss: 0.8372\n",
      "Train Epoch: 19 [600/900 (66.66666666666667%)]\tLoss: 0.6528\n",
      "Train Epoch: 19 [700/900 (77.77777777777777%)]\tLoss: 0.7945\n",
      "Train Epoch: 19 [800/900 (88.88888888888889%)]\tLoss: 0.7021\n",
      "Train Epoch: 19 [900/900 (100.0%)]\tLoss: 0.6290\n",
      "Done epoch #19, time for this epoch: 64.14185166358948s\n",
      "Start epoch #20, learning rate for this epoch: 0.0003773536025353072\n",
      "Train Epoch: 20 [100/900 (11.11111111111111%)]\tLoss: 0.6158\n",
      "Train Epoch: 20 [200/900 (22.22222222222222%)]\tLoss: 0.5997\n",
      "Train Epoch: 20 [300/900 (33.333333333333336%)]\tLoss: 0.6481\n",
      "Train Epoch: 20 [400/900 (44.44444444444444%)]\tLoss: 0.6368\n",
      "Train Epoch: 20 [500/900 (55.55555555555556%)]\tLoss: 0.7864\n",
      "Train Epoch: 20 [600/900 (66.66666666666667%)]\tLoss: 0.6050\n",
      "Train Epoch: 20 [700/900 (77.77777777777777%)]\tLoss: 0.6851\n",
      "Train Epoch: 20 [800/900 (88.88888888888889%)]\tLoss: 0.4578\n",
      "Train Epoch: 20 [900/900 (100.0%)]\tLoss: 0.7258\n",
      "Done epoch #20, time for this epoch: 64.6176655292511s\n",
      "Start epoch #21, learning rate for this epoch: 0.0003584859224085418\n",
      "Train Epoch: 21 [100/900 (11.11111111111111%)]\tLoss: 0.5973\n",
      "Train Epoch: 21 [200/900 (22.22222222222222%)]\tLoss: 0.6132\n",
      "Train Epoch: 21 [300/900 (33.333333333333336%)]\tLoss: 0.6073\n",
      "Train Epoch: 21 [400/900 (44.44444444444444%)]\tLoss: 0.7130\n",
      "Train Epoch: 21 [500/900 (55.55555555555556%)]\tLoss: 0.9059\n",
      "Train Epoch: 21 [600/900 (66.66666666666667%)]\tLoss: 0.6283\n",
      "Train Epoch: 21 [700/900 (77.77777777777777%)]\tLoss: 0.6290\n",
      "Train Epoch: 21 [800/900 (88.88888888888889%)]\tLoss: 0.7251\n",
      "Train Epoch: 21 [900/900 (100.0%)]\tLoss: 0.7360\n",
      "Done epoch #21, time for this epoch: 64.78510284423828s\n",
      "Start epoch #22, learning rate for this epoch: 0.0003405616262881147\n",
      "Train Epoch: 22 [100/900 (11.11111111111111%)]\tLoss: 0.7915\n",
      "Train Epoch: 22 [200/900 (22.22222222222222%)]\tLoss: 0.6011\n",
      "Train Epoch: 22 [300/900 (33.333333333333336%)]\tLoss: 0.5969\n",
      "Train Epoch: 22 [400/900 (44.44444444444444%)]\tLoss: 0.6013\n",
      "Train Epoch: 22 [500/900 (55.55555555555556%)]\tLoss: 0.6825\n",
      "Train Epoch: 22 [600/900 (66.66666666666667%)]\tLoss: 0.7167\n",
      "Train Epoch: 22 [700/900 (77.77777777777777%)]\tLoss: 0.6075\n",
      "Train Epoch: 22 [800/900 (88.88888888888889%)]\tLoss: 0.5859\n",
      "Train Epoch: 22 [900/900 (100.0%)]\tLoss: 0.8203\n",
      "Done epoch #22, time for this epoch: 64.13795876502991s\n",
      "Start epoch #23, learning rate for this epoch: 0.00032353354497370894\n",
      "Train Epoch: 23 [100/900 (11.11111111111111%)]\tLoss: 0.5578\n",
      "Train Epoch: 23 [200/900 (22.22222222222222%)]\tLoss: 0.6458\n",
      "Train Epoch: 23 [300/900 (33.333333333333336%)]\tLoss: 0.8774\n",
      "Train Epoch: 23 [400/900 (44.44444444444444%)]\tLoss: 0.5802\n",
      "Train Epoch: 23 [500/900 (55.55555555555556%)]\tLoss: 0.7028\n",
      "Train Epoch: 23 [600/900 (66.66666666666667%)]\tLoss: 0.5731\n",
      "Train Epoch: 23 [700/900 (77.77777777777777%)]\tLoss: 0.6703\n",
      "Train Epoch: 23 [800/900 (88.88888888888889%)]\tLoss: 0.6568\n",
      "Train Epoch: 23 [900/900 (100.0%)]\tLoss: 0.5860\n",
      "Done epoch #23, time for this epoch: 64.26900124549866s\n",
      "Start epoch #24, learning rate for this epoch: 0.00030735686772502346\n",
      "Train Epoch: 24 [100/900 (11.11111111111111%)]\tLoss: 0.7518\n",
      "Train Epoch: 24 [200/900 (22.22222222222222%)]\tLoss: 0.6218\n",
      "Train Epoch: 24 [300/900 (33.333333333333336%)]\tLoss: 0.5671\n",
      "Train Epoch: 24 [400/900 (44.44444444444444%)]\tLoss: 0.7953\n",
      "Train Epoch: 24 [500/900 (55.55555555555556%)]\tLoss: 0.6208\n",
      "Train Epoch: 24 [600/900 (66.66666666666667%)]\tLoss: 0.7894\n",
      "Train Epoch: 24 [700/900 (77.77777777777777%)]\tLoss: 0.9253\n",
      "Train Epoch: 24 [800/900 (88.88888888888889%)]\tLoss: 0.5946\n",
      "Train Epoch: 24 [900/900 (100.0%)]\tLoss: 0.6343\n",
      "Done epoch #24, time for this epoch: 64.15062093734741s\n",
      "Start epoch #25, learning rate for this epoch: 0.00029198902433877225\n",
      "Train Epoch: 25 [100/900 (11.11111111111111%)]\tLoss: 0.6392\n",
      "Train Epoch: 25 [200/900 (22.22222222222222%)]\tLoss: 0.7494\n",
      "Train Epoch: 25 [300/900 (33.333333333333336%)]\tLoss: 0.5277\n",
      "Train Epoch: 25 [400/900 (44.44444444444444%)]\tLoss: 0.6646\n",
      "Train Epoch: 25 [500/900 (55.55555555555556%)]\tLoss: 0.5738\n",
      "Train Epoch: 25 [600/900 (66.66666666666667%)]\tLoss: 0.6708\n",
      "Train Epoch: 25 [700/900 (77.77777777777777%)]\tLoss: 0.6727\n",
      "Train Epoch: 25 [800/900 (88.88888888888889%)]\tLoss: 0.8356\n",
      "Train Epoch: 25 [900/900 (100.0%)]\tLoss: 0.6036\n",
      "Done epoch #25, time for this epoch: 63.28922915458679s\n",
      "Start epoch #26, learning rate for this epoch: 0.00027738957312183364\n",
      "Train Epoch: 26 [100/900 (11.11111111111111%)]\tLoss: 0.7202\n",
      "Train Epoch: 26 [200/900 (22.22222222222222%)]\tLoss: 0.7185\n",
      "Train Epoch: 26 [300/900 (33.333333333333336%)]\tLoss: 0.6835\n",
      "Train Epoch: 26 [400/900 (44.44444444444444%)]\tLoss: 0.6297\n",
      "Train Epoch: 26 [500/900 (55.55555555555556%)]\tLoss: 0.6208\n",
      "Train Epoch: 26 [600/900 (66.66666666666667%)]\tLoss: 0.5989\n",
      "Train Epoch: 26 [700/900 (77.77777777777777%)]\tLoss: 0.6341\n",
      "Train Epoch: 26 [800/900 (88.88888888888889%)]\tLoss: 0.4956\n",
      "Train Epoch: 26 [900/900 (100.0%)]\tLoss: 0.6068\n",
      "Done epoch #26, time for this epoch: 64.3262791633606s\n",
      "Start epoch #27, learning rate for this epoch: 0.0002635200944657419\n",
      "Train Epoch: 27 [100/900 (11.11111111111111%)]\tLoss: 0.6698\n",
      "Train Epoch: 27 [200/900 (22.22222222222222%)]\tLoss: 0.5670\n",
      "Train Epoch: 27 [300/900 (33.333333333333336%)]\tLoss: 0.6798\n",
      "Train Epoch: 27 [400/900 (44.44444444444444%)]\tLoss: 0.6352\n",
      "Train Epoch: 27 [500/900 (55.55555555555556%)]\tLoss: 0.9053\n",
      "Train Epoch: 27 [600/900 (66.66666666666667%)]\tLoss: 0.5565\n",
      "Train Epoch: 27 [700/900 (77.77777777777777%)]\tLoss: 0.6679\n",
      "Train Epoch: 27 [800/900 (88.88888888888889%)]\tLoss: 0.6137\n",
      "Train Epoch: 27 [900/900 (100.0%)]\tLoss: 0.8118\n",
      "Done epoch #27, time for this epoch: 63.81342887878418s\n",
      "Start epoch #28, learning rate for this epoch: 0.0002503440897424548\n",
      "Train Epoch: 28 [100/900 (11.11111111111111%)]\tLoss: 0.5786\n",
      "Train Epoch: 28 [200/900 (22.22222222222222%)]\tLoss: 0.6426\n",
      "Train Epoch: 28 [300/900 (33.333333333333336%)]\tLoss: 0.7573\n",
      "Train Epoch: 28 [400/900 (44.44444444444444%)]\tLoss: 0.6593\n",
      "Train Epoch: 28 [500/900 (55.55555555555556%)]\tLoss: 0.5634\n",
      "Train Epoch: 28 [600/900 (66.66666666666667%)]\tLoss: 0.6170\n",
      "Train Epoch: 28 [700/900 (77.77777777777777%)]\tLoss: 0.6053\n",
      "Train Epoch: 28 [800/900 (88.88888888888889%)]\tLoss: 0.5856\n",
      "Train Epoch: 28 [900/900 (100.0%)]\tLoss: 0.6194\n",
      "Done epoch #28, time for this epoch: 64.8046863079071s\n",
      "Start epoch #29, learning rate for this epoch: 0.00023782688525533205\n",
      "Train Epoch: 29 [100/900 (11.11111111111111%)]\tLoss: 0.8283\n",
      "Train Epoch: 29 [200/900 (22.22222222222222%)]\tLoss: 0.5494\n",
      "Train Epoch: 29 [300/900 (33.333333333333336%)]\tLoss: 0.5479\n",
      "Train Epoch: 29 [400/900 (44.44444444444444%)]\tLoss: 0.6352\n",
      "Train Epoch: 29 [500/900 (55.55555555555556%)]\tLoss: 0.5641\n",
      "Train Epoch: 29 [600/900 (66.66666666666667%)]\tLoss: 0.6311\n",
      "Train Epoch: 29 [700/900 (77.77777777777777%)]\tLoss: 0.4851\n",
      "Train Epoch: 29 [800/900 (88.88888888888889%)]\tLoss: 0.6327\n",
      "Train Epoch: 29 [900/900 (100.0%)]\tLoss: 0.5641\n",
      "Done epoch #29, time for this epoch: 65.14130306243896s\n",
      "Start epoch #30, learning rate for this epoch: 0.00022593554099256544\n",
      "Train Epoch: 30 [100/900 (11.11111111111111%)]\tLoss: 0.5991\n",
      "Train Epoch: 30 [200/900 (22.22222222222222%)]\tLoss: 0.6307\n",
      "Train Epoch: 30 [300/900 (33.333333333333336%)]\tLoss: 0.7177\n",
      "Train Epoch: 30 [400/900 (44.44444444444444%)]\tLoss: 0.6022\n",
      "Train Epoch: 30 [500/900 (55.55555555555556%)]\tLoss: 0.6213\n",
      "Train Epoch: 30 [600/900 (66.66666666666667%)]\tLoss: 0.6258\n",
      "Train Epoch: 30 [700/900 (77.77777777777777%)]\tLoss: 0.6716\n",
      "Train Epoch: 30 [800/900 (88.88888888888889%)]\tLoss: 0.5318\n",
      "Train Epoch: 30 [900/900 (100.0%)]\tLoss: 0.7346\n",
      "Done epoch #30, time for this epoch: 64.0213828086853s\n",
      "Start epoch #31, learning rate for this epoch: 0.00021463876394293716\n",
      "Train Epoch: 31 [100/900 (11.11111111111111%)]\tLoss: 0.6706\n",
      "Train Epoch: 31 [200/900 (22.22222222222222%)]\tLoss: 0.6645\n",
      "Train Epoch: 31 [300/900 (33.333333333333336%)]\tLoss: 0.5946\n",
      "Train Epoch: 31 [400/900 (44.44444444444444%)]\tLoss: 0.5846\n",
      "Train Epoch: 31 [500/900 (55.55555555555556%)]\tLoss: 0.6146\n",
      "Train Epoch: 31 [600/900 (66.66666666666667%)]\tLoss: 0.8086\n",
      "Train Epoch: 31 [700/900 (77.77777777777777%)]\tLoss: 0.5921\n",
      "Train Epoch: 31 [800/900 (88.88888888888889%)]\tLoss: 0.4868\n",
      "Train Epoch: 31 [900/900 (100.0%)]\tLoss: 0.6358\n",
      "Done epoch #31, time for this epoch: 64.77378153800964s\n",
      "Start epoch #32, learning rate for this epoch: 0.0002039068257457903\n",
      "Train Epoch: 32 [100/900 (11.11111111111111%)]\tLoss: 0.4977\n",
      "Train Epoch: 32 [200/900 (22.22222222222222%)]\tLoss: 0.4984\n",
      "Train Epoch: 32 [300/900 (33.333333333333336%)]\tLoss: 0.6815\n",
      "Train Epoch: 32 [400/900 (44.44444444444444%)]\tLoss: 0.6072\n",
      "Train Epoch: 32 [500/900 (55.55555555555556%)]\tLoss: 0.5895\n",
      "Train Epoch: 32 [600/900 (66.66666666666667%)]\tLoss: 0.7634\n",
      "Train Epoch: 32 [700/900 (77.77777777777777%)]\tLoss: 0.6228\n",
      "Train Epoch: 32 [800/900 (88.88888888888889%)]\tLoss: 0.9025\n",
      "Train Epoch: 32 [900/900 (100.0%)]\tLoss: 0.5939\n",
      "Done epoch #32, time for this epoch: 64.60517644882202s\n",
      "Start epoch #33, learning rate for this epoch: 0.00019371148445850077\n",
      "Train Epoch: 33 [100/900 (11.11111111111111%)]\tLoss: 0.6479\n",
      "Train Epoch: 33 [200/900 (22.22222222222222%)]\tLoss: 0.5393\n",
      "Train Epoch: 33 [300/900 (33.333333333333336%)]\tLoss: 0.5617\n",
      "Train Epoch: 33 [400/900 (44.44444444444444%)]\tLoss: 0.6315\n",
      "Train Epoch: 33 [500/900 (55.55555555555556%)]\tLoss: 0.5837\n",
      "Train Epoch: 33 [600/900 (66.66666666666667%)]\tLoss: 0.8522\n",
      "Train Epoch: 33 [700/900 (77.77777777777777%)]\tLoss: 0.5100\n",
      "Train Epoch: 33 [800/900 (88.88888888888889%)]\tLoss: 0.6056\n",
      "Train Epoch: 33 [900/900 (100.0%)]\tLoss: 0.6420\n",
      "Done epoch #33, time for this epoch: 65.1291925907135s\n",
      "Start epoch #34, learning rate for this epoch: 0.00018402591023557573\n",
      "Train Epoch: 34 [100/900 (11.11111111111111%)]\tLoss: 0.5967\n",
      "Train Epoch: 34 [200/900 (22.22222222222222%)]\tLoss: 0.6480\n",
      "Train Epoch: 34 [300/900 (33.333333333333336%)]\tLoss: 0.7110\n",
      "Train Epoch: 34 [400/900 (44.44444444444444%)]\tLoss: 0.6978\n",
      "Train Epoch: 34 [500/900 (55.55555555555556%)]\tLoss: 0.6039\n",
      "Train Epoch: 34 [600/900 (66.66666666666667%)]\tLoss: 0.5767\n",
      "Train Epoch: 34 [700/900 (77.77777777777777%)]\tLoss: 0.7396\n",
      "Train Epoch: 34 [800/900 (88.88888888888889%)]\tLoss: 0.5255\n",
      "Train Epoch: 34 [900/900 (100.0%)]\tLoss: 0.4798\n",
      "Done epoch #34, time for this epoch: 64.98441743850708s\n",
      "Start epoch #35, learning rate for this epoch: 0.00017482461472379692\n",
      "Train Epoch: 35 [100/900 (11.11111111111111%)]\tLoss: 0.5641\n",
      "Train Epoch: 35 [200/900 (22.22222222222222%)]\tLoss: 0.6944\n",
      "Train Epoch: 35 [300/900 (33.333333333333336%)]\tLoss: 0.8415\n",
      "Train Epoch: 35 [400/900 (44.44444444444444%)]\tLoss: 0.5600\n",
      "Train Epoch: 35 [500/900 (55.55555555555556%)]\tLoss: 0.5981\n",
      "Train Epoch: 35 [600/900 (66.66666666666667%)]\tLoss: 0.7192\n",
      "Train Epoch: 35 [700/900 (77.77777777777777%)]\tLoss: 0.4345\n",
      "Train Epoch: 35 [800/900 (88.88888888888889%)]\tLoss: 0.5274\n",
      "Train Epoch: 35 [900/900 (100.0%)]\tLoss: 0.5424\n",
      "Done epoch #35, time for this epoch: 64.54749941825867s\n",
      "Start epoch #36, learning rate for this epoch: 0.00016608338398760707\n",
      "Train Epoch: 36 [100/900 (11.11111111111111%)]\tLoss: 0.6927\n",
      "Train Epoch: 36 [200/900 (22.22222222222222%)]\tLoss: 0.6487\n",
      "Train Epoch: 36 [300/900 (33.333333333333336%)]\tLoss: 0.5801\n",
      "Train Epoch: 36 [400/900 (44.44444444444444%)]\tLoss: 0.6380\n",
      "Train Epoch: 36 [500/900 (55.55555555555556%)]\tLoss: 0.6609\n",
      "Train Epoch: 36 [600/900 (66.66666666666667%)]\tLoss: 0.4886\n",
      "Train Epoch: 36 [700/900 (77.77777777777777%)]\tLoss: 0.5540\n",
      "Train Epoch: 36 [800/900 (88.88888888888889%)]\tLoss: 0.6302\n",
      "Train Epoch: 36 [900/900 (100.0%)]\tLoss: 0.8372\n",
      "Done epoch #36, time for this epoch: 64.50406312942505s\n",
      "Start epoch #37, learning rate for this epoch: 0.0001577792147882267\n",
      "Train Epoch: 37 [100/900 (11.11111111111111%)]\tLoss: 0.7288\n",
      "Train Epoch: 37 [200/900 (22.22222222222222%)]\tLoss: 0.5076\n",
      "Train Epoch: 37 [300/900 (33.333333333333336%)]\tLoss: 0.4519\n",
      "Train Epoch: 37 [400/900 (44.44444444444444%)]\tLoss: 0.5707\n",
      "Train Epoch: 37 [500/900 (55.55555555555556%)]\tLoss: 0.4666\n",
      "Train Epoch: 37 [600/900 (66.66666666666667%)]\tLoss: 0.5862\n",
      "Train Epoch: 37 [700/900 (77.77777777777777%)]\tLoss: 0.6184\n",
      "Train Epoch: 37 [800/900 (88.88888888888889%)]\tLoss: 0.5535\n",
      "Train Epoch: 37 [900/900 (100.0%)]\tLoss: 0.4464\n",
      "Done epoch #37, time for this epoch: 63.812095403671265s\n",
      "Start epoch #38, learning rate for this epoch: 0.00014989025404881537\n",
      "Train Epoch: 38 [100/900 (11.11111111111111%)]\tLoss: 0.6408\n",
      "Train Epoch: 38 [200/900 (22.22222222222222%)]\tLoss: 0.5663\n",
      "Train Epoch: 38 [300/900 (33.333333333333336%)]\tLoss: 0.5420\n",
      "Train Epoch: 38 [400/900 (44.44444444444444%)]\tLoss: 0.7080\n",
      "Train Epoch: 38 [500/900 (55.55555555555556%)]\tLoss: 0.5971\n",
      "Train Epoch: 38 [600/900 (66.66666666666667%)]\tLoss: 0.5552\n",
      "Train Epoch: 38 [700/900 (77.77777777777777%)]\tLoss: 0.5863\n",
      "Train Epoch: 38 [800/900 (88.88888888888889%)]\tLoss: 0.5472\n",
      "Train Epoch: 38 [900/900 (100.0%)]\tLoss: 0.6174\n",
      "Done epoch #38, time for this epoch: 64.9240174293518s\n",
      "Start epoch #39, learning rate for this epoch: 0.00014239574134637458\n",
      "Train Epoch: 39 [100/900 (11.11111111111111%)]\tLoss: 0.7378\n",
      "Train Epoch: 39 [200/900 (22.22222222222222%)]\tLoss: 0.6450\n",
      "Train Epoch: 39 [300/900 (33.333333333333336%)]\tLoss: 0.5819\n",
      "Train Epoch: 39 [400/900 (44.44444444444444%)]\tLoss: 0.5520\n",
      "Train Epoch: 39 [500/900 (55.55555555555556%)]\tLoss: 0.4901\n",
      "Train Epoch: 39 [600/900 (66.66666666666667%)]\tLoss: 0.5606\n",
      "Train Epoch: 39 [700/900 (77.77777777777777%)]\tLoss: 0.6048\n",
      "Train Epoch: 39 [800/900 (88.88888888888889%)]\tLoss: 0.5871\n",
      "Train Epoch: 39 [900/900 (100.0%)]\tLoss: 0.6403\n",
      "Done epoch #39, time for this epoch: 68.61376357078552s\n",
      "Start epoch #40, learning rate for this epoch: 0.00013527595427905584\n",
      "Train Epoch: 40 [100/900 (11.11111111111111%)]\tLoss: 0.5765\n",
      "Train Epoch: 40 [200/900 (22.22222222222222%)]\tLoss: 0.5527\n",
      "Train Epoch: 40 [300/900 (33.333333333333336%)]\tLoss: 0.4815\n",
      "Train Epoch: 40 [400/900 (44.44444444444444%)]\tLoss: 0.5843\n",
      "Train Epoch: 40 [500/900 (55.55555555555556%)]\tLoss: 0.5640\n",
      "Train Epoch: 40 [600/900 (66.66666666666667%)]\tLoss: 0.4730\n",
      "Train Epoch: 40 [700/900 (77.77777777777777%)]\tLoss: 0.6118\n",
      "Train Epoch: 40 [800/900 (88.88888888888889%)]\tLoss: 0.5807\n",
      "Train Epoch: 40 [900/900 (100.0%)]\tLoss: 0.6022\n",
      "Done epoch #40, time for this epoch: 68.00445365905762s\n",
      "Start epoch #41, learning rate for this epoch: 0.00012851215656510304\n",
      "Train Epoch: 41 [100/900 (11.11111111111111%)]\tLoss: 0.5517\n",
      "Train Epoch: 41 [200/900 (22.22222222222222%)]\tLoss: 0.5711\n",
      "Train Epoch: 41 [300/900 (33.333333333333336%)]\tLoss: 0.5327\n",
      "Train Epoch: 41 [400/900 (44.44444444444444%)]\tLoss: 0.7036\n",
      "Train Epoch: 41 [500/900 (55.55555555555556%)]\tLoss: 0.6077\n",
      "Train Epoch: 41 [600/900 (66.66666666666667%)]\tLoss: 0.5542\n",
      "Train Epoch: 41 [700/900 (77.77777777777777%)]\tLoss: 0.6395\n",
      "Train Epoch: 41 [800/900 (88.88888888888889%)]\tLoss: 0.5745\n",
      "Train Epoch: 41 [900/900 (100.0%)]\tLoss: 0.6115\n",
      "Done epoch #41, time for this epoch: 68.0856020450592s\n",
      "Start epoch #42, learning rate for this epoch: 0.00012208654873684788\n",
      "Train Epoch: 42 [100/900 (11.11111111111111%)]\tLoss: 0.5730\n",
      "Train Epoch: 42 [200/900 (22.22222222222222%)]\tLoss: 0.5964\n",
      "Train Epoch: 42 [300/900 (33.333333333333336%)]\tLoss: 0.4252\n",
      "Train Epoch: 42 [400/900 (44.44444444444444%)]\tLoss: 0.5522\n",
      "Train Epoch: 42 [500/900 (55.55555555555556%)]\tLoss: 0.5135\n",
      "Train Epoch: 42 [600/900 (66.66666666666667%)]\tLoss: 0.4546\n",
      "Train Epoch: 42 [700/900 (77.77777777777777%)]\tLoss: 0.5539\n",
      "Train Epoch: 42 [800/900 (88.88888888888889%)]\tLoss: 0.5903\n",
      "Train Epoch: 42 [900/900 (100.0%)]\tLoss: 0.6124\n",
      "Done epoch #42, time for this epoch: 69.51032185554504s\n",
      "Start epoch #43, learning rate for this epoch: 0.00011598222130000548\n",
      "Train Epoch: 43 [100/900 (11.11111111111111%)]\tLoss: 0.5280\n",
      "Train Epoch: 43 [200/900 (22.22222222222222%)]\tLoss: 0.6223\n",
      "Train Epoch: 43 [300/900 (33.333333333333336%)]\tLoss: 0.5861\n",
      "Train Epoch: 43 [400/900 (44.44444444444444%)]\tLoss: 0.5653\n",
      "Train Epoch: 43 [500/900 (55.55555555555556%)]\tLoss: 0.5622\n",
      "Train Epoch: 43 [600/900 (66.66666666666667%)]\tLoss: 0.6474\n",
      "Train Epoch: 43 [700/900 (77.77777777777777%)]\tLoss: 0.4155\n",
      "Train Epoch: 43 [800/900 (88.88888888888889%)]\tLoss: 0.4850\n",
      "Train Epoch: 43 [900/900 (100.0%)]\tLoss: 0.6692\n",
      "Done epoch #43, time for this epoch: 67.71621537208557s\n",
      "Start epoch #44, learning rate for this epoch: 0.00011018311023500519\n",
      "Train Epoch: 44 [100/900 (11.11111111111111%)]\tLoss: 0.5379\n",
      "Train Epoch: 44 [200/900 (22.22222222222222%)]\tLoss: 0.5861\n",
      "Train Epoch: 44 [300/900 (33.333333333333336%)]\tLoss: 0.5713\n",
      "Train Epoch: 44 [400/900 (44.44444444444444%)]\tLoss: 0.5151\n",
      "Train Epoch: 44 [500/900 (55.55555555555556%)]\tLoss: 0.4247\n",
      "Train Epoch: 44 [600/900 (66.66666666666667%)]\tLoss: 0.4492\n",
      "Train Epoch: 44 [700/900 (77.77777777777777%)]\tLoss: 0.5471\n",
      "Train Epoch: 44 [800/900 (88.88888888888889%)]\tLoss: 0.5236\n",
      "Train Epoch: 44 [900/900 (100.0%)]\tLoss: 0.4993\n",
      "Done epoch #44, time for this epoch: 68.01513934135437s\n",
      "Start epoch #45, learning rate for this epoch: 0.00010467395472325493\n",
      "Train Epoch: 45 [100/900 (11.11111111111111%)]\tLoss: 0.5915\n",
      "Train Epoch: 45 [200/900 (22.22222222222222%)]\tLoss: 0.4477\n",
      "Train Epoch: 45 [300/900 (33.333333333333336%)]\tLoss: 0.6392\n",
      "Train Epoch: 45 [400/900 (44.44444444444444%)]\tLoss: 0.7022\n",
      "Train Epoch: 45 [500/900 (55.55555555555556%)]\tLoss: 0.5537\n",
      "Train Epoch: 45 [600/900 (66.66666666666667%)]\tLoss: 0.5369\n",
      "Train Epoch: 45 [700/900 (77.77777777777777%)]\tLoss: 0.4954\n",
      "Train Epoch: 45 [800/900 (88.88888888888889%)]\tLoss: 0.3862\n",
      "Train Epoch: 45 [900/900 (100.0%)]\tLoss: 0.5190\n",
      "Done epoch #45, time for this epoch: 67.03042793273926s\n",
      "Start epoch #46, learning rate for this epoch: 9.944025698709218e-05\n",
      "Train Epoch: 46 [100/900 (11.11111111111111%)]\tLoss: 0.4954\n",
      "Train Epoch: 46 [200/900 (22.22222222222222%)]\tLoss: 0.5752\n",
      "Train Epoch: 46 [300/900 (33.333333333333336%)]\tLoss: 0.5805\n",
      "Train Epoch: 46 [400/900 (44.44444444444444%)]\tLoss: 0.7143\n",
      "Train Epoch: 46 [500/900 (55.55555555555556%)]\tLoss: 0.4960\n",
      "Train Epoch: 46 [600/900 (66.66666666666667%)]\tLoss: 0.5025\n",
      "Train Epoch: 46 [700/900 (77.77777777777777%)]\tLoss: 0.5615\n",
      "Train Epoch: 46 [800/900 (88.88888888888889%)]\tLoss: 0.4844\n",
      "Train Epoch: 46 [900/900 (100.0%)]\tLoss: 0.5099\n",
      "Done epoch #46, time for this epoch: 66.59748792648315s\n",
      "Start epoch #47, learning rate for this epoch: 9.446824413773756e-05\n",
      "Train Epoch: 47 [100/900 (11.11111111111111%)]\tLoss: 0.5919\n",
      "Train Epoch: 47 [200/900 (22.22222222222222%)]\tLoss: 0.5817\n",
      "Train Epoch: 47 [300/900 (33.333333333333336%)]\tLoss: 0.5800\n",
      "Train Epoch: 47 [400/900 (44.44444444444444%)]\tLoss: 0.5639\n",
      "Train Epoch: 47 [500/900 (55.55555555555556%)]\tLoss: 0.5459\n",
      "Train Epoch: 47 [600/900 (66.66666666666667%)]\tLoss: 0.5846\n",
      "Train Epoch: 47 [700/900 (77.77777777777777%)]\tLoss: 0.6412\n",
      "Train Epoch: 47 [800/900 (88.88888888888889%)]\tLoss: 0.5706\n",
      "Train Epoch: 47 [900/900 (100.0%)]\tLoss: 0.5729\n",
      "Done epoch #47, time for this epoch: 66.81725215911865s\n",
      "Start epoch #48, learning rate for this epoch: 8.974483193085068e-05\n",
      "Train Epoch: 48 [100/900 (11.11111111111111%)]\tLoss: 0.5964\n",
      "Train Epoch: 48 [200/900 (22.22222222222222%)]\tLoss: 0.5807\n",
      "Train Epoch: 48 [300/900 (33.333333333333336%)]\tLoss: 0.3895\n",
      "Train Epoch: 48 [400/900 (44.44444444444444%)]\tLoss: 0.6044\n",
      "Train Epoch: 48 [500/900 (55.55555555555556%)]\tLoss: 0.5610\n",
      "Train Epoch: 48 [600/900 (66.66666666666667%)]\tLoss: 0.6105\n",
      "Train Epoch: 48 [700/900 (77.77777777777777%)]\tLoss: 0.5147\n",
      "Train Epoch: 48 [800/900 (88.88888888888889%)]\tLoss: 0.5047\n",
      "Train Epoch: 48 [900/900 (100.0%)]\tLoss: 0.5866\n",
      "Done epoch #48, time for this epoch: 66.4823751449585s\n",
      "Start epoch #49, learning rate for this epoch: 8.525759033430814e-05\n",
      "Train Epoch: 49 [100/900 (11.11111111111111%)]\tLoss: 0.4790\n",
      "Train Epoch: 49 [200/900 (22.22222222222222%)]\tLoss: 0.5882\n",
      "Train Epoch: 49 [300/900 (33.333333333333336%)]\tLoss: 0.5216\n",
      "Train Epoch: 49 [400/900 (44.44444444444444%)]\tLoss: 0.5978\n",
      "Train Epoch: 49 [500/900 (55.55555555555556%)]\tLoss: 0.3195\n",
      "Train Epoch: 49 [600/900 (66.66666666666667%)]\tLoss: 0.5762\n",
      "Train Epoch: 49 [700/900 (77.77777777777777%)]\tLoss: 0.5417\n",
      "Train Epoch: 49 [800/900 (88.88888888888889%)]\tLoss: 0.6525\n",
      "Train Epoch: 49 [900/900 (100.0%)]\tLoss: 0.3761\n",
      "Done epoch #49, time for this epoch: 66.59770917892456s\n",
      "Start epoch #50, learning rate for this epoch: 8.099471081759274e-05\n",
      "Train Epoch: 50 [100/900 (11.11111111111111%)]\tLoss: 0.4452\n",
      "Train Epoch: 50 [200/900 (22.22222222222222%)]\tLoss: 0.5685\n",
      "Train Epoch: 50 [300/900 (33.333333333333336%)]\tLoss: 0.4955\n",
      "Train Epoch: 50 [400/900 (44.44444444444444%)]\tLoss: 0.5394\n",
      "Train Epoch: 50 [500/900 (55.55555555555556%)]\tLoss: 0.5706\n",
      "Train Epoch: 50 [600/900 (66.66666666666667%)]\tLoss: 0.5850\n",
      "Train Epoch: 50 [700/900 (77.77777777777777%)]\tLoss: 0.5091\n",
      "Train Epoch: 50 [800/900 (88.88888888888889%)]\tLoss: 0.6138\n",
      "Train Epoch: 50 [900/900 (100.0%)]\tLoss: 0.6061\n",
      "Done epoch #50, time for this epoch: 65.94435930252075s\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_loss_array = []\n",
    "test_loss_array = []\n",
    "last_loss = 9999999999999\n",
    "for epoch in range(epochs):\n",
    "    train_loss_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    (train_loss_epoch, test_loss_epoch) = train(train_dataloader, \n",
    "                                              valid_dataloader, \n",
    "                                              learing_rate_scheduler, epoch, display_step)\n",
    "    \n",
    "    if test_loss_epoch < last_loss:\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        last_loss = test_loss_epoch\n",
    "\n",
    "    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch, \"Learning rate\": optimizer.param_groups[0][\"lr\"]})\n",
    "    learing_rate_scheduler.step()\n",
    "    train_loss_array.append(train_loss_epoch)\n",
    "    test_loss_array.append(test_loss_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:24:58.567668Z",
     "iopub.status.busy": "2024-11-24T14:24:58.567448Z",
     "iopub.status.idle": "2024-11-24T14:24:58.795676Z",
     "shell.execute_reply": "2024-11-24T14:24:58.794630Z",
     "shell.execute_reply.started": "2024-11-24T14:24:58.567629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Collect garbage and clear cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:34:55.407764Z",
     "iopub.status.busy": "2024-11-24T14:34:55.406960Z",
     "iopub.status.idle": "2024-11-24T14:34:55.567948Z",
     "shell.execute_reply": "2024-11-24T14:34:55.567011Z",
     "shell.execute_reply.started": "2024-11-24T14:34:55.407735Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(checkpoint_path, weights_only=True))\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:39:47.558333Z",
     "iopub.status.busy": "2024-11-24T14:39:47.558002Z",
     "iopub.status.idle": "2024-11-24T14:39:47.571942Z",
     "shell.execute_reply": "2024-11-24T14:39:47.570830Z",
     "shell.execute_reply.started": "2024-11-24T14:39:47.558297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNetTestDataClass(Dataset):\n",
    "    def __init__(self, images_path, transform):\n",
    "        super(UNetTestDataClass, self).__init__()\n",
    "        \n",
    "        images_list = os.listdir(images_path)\n",
    "        images_list = [images_path+i for i in images_list]\n",
    "        \n",
    "        self.images_list = images_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_list[index]\n",
    "        data = Image.open(img_path)\n",
    "        h = data.size[1]\n",
    "        w = data.size[0]\n",
    "        data = self.transform(data) / 255        \n",
    "        return data, img_path, h, w\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:39:47.573347Z",
     "iopub.status.busy": "2024-11-24T14:39:47.573039Z",
     "iopub.status.idle": "2024-11-24T14:39:47.585180Z",
     "shell.execute_reply": "2024-11-24T14:39:47.584275Z",
     "shell.execute_reply.started": "2024-11-24T14:39:47.573319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\n",
    "path = '/test/test/'\n",
    "unet_test_dataset = UNetTestDataClass(path, transform)\n",
    "test_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:39:52.040296Z",
     "iopub.status.busy": "2024-11-24T14:39:52.040017Z",
     "iopub.status.idle": "2024-11-24T14:41:09.381478Z",
     "shell.execute_reply": "2024-11-24T14:41:09.380460Z",
     "shell.execute_reply.started": "2024-11-24T14:39:52.040266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#if not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n",
    "#    os.mkdir(\"/kaggle/working/predicted_masks\")\n",
    "for _, (img, path, h, w) in enumerate(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        predicted_mask = model(img)\n",
    "    for i in range(len(path)):\n",
    "        image_id = path[i].split('/')[-1].split('.')[0]\n",
    "        filename = image_id + \".png\"\n",
    "        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n",
    "        mask2img.save(os.path.join(\"/test_gt/test_gt\", filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T14:41:09.382938Z",
     "iopub.status.busy": "2024-11-24T14:41:09.382687Z",
     "iopub.status.idle": "2024-11-24T14:41:12.094274Z",
     "shell.execute_reply": "2024-11-24T14:41:12.093413Z",
     "shell.execute_reply.started": "2024-11-24T14:41:09.382916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/predicted_masks/998906d3694abb47953b0e4909384b57.png\n",
      "/kaggle/working/predicted_masks/b70dd094a7f32574d6c748c41743c6c0.png\n",
      "/kaggle/working/predicted_masks/97e1c0e9082ea2c193ac8d551c149b60.png\n",
      "/kaggle/working/predicted_masks/d6bf62f215f0da4ad3a7ab8df9da7386.png\n",
      "/kaggle/working/predicted_masks/3c3ca4d5060a633a8d5b2b2b55157b77.png\n",
      "/kaggle/working/predicted_masks/fe1f119f21b248d152b672ab3492fc62.png\n",
      "/kaggle/working/predicted_masks/0626ab4ec3d46e602b296cc5cfd263f1.png\n",
      "/kaggle/working/predicted_masks/e2cd066b9fdbc3bbc04a3afe1f119f21.png\n",
      "/kaggle/working/predicted_masks/8fa8625605da2023387fd56c04414eaa.png\n",
      "/kaggle/working/predicted_masks/c656702fa602bb3c7abacdbd7e6afd56.png\n",
      "/kaggle/working/predicted_masks/2d9e593b6be1ac29adbe86f03d900fd1.png\n",
      "/kaggle/working/predicted_masks/eb1ef57af2ed9fbb63b28163a745959c.png\n",
      "/kaggle/working/predicted_masks/5e8f14e1e0ae936de314f2d95e6c487f.png\n",
      "/kaggle/working/predicted_masks/4e8bfb905b78a91391adc0bb223c4eaf.png\n",
      "/kaggle/working/predicted_masks/e56a6d9ba9d45c3dbc695325ded465ef.png\n",
      "/kaggle/working/predicted_masks/2ed9fbb63b28163a745959c03983064a.png\n",
      "/kaggle/working/predicted_masks/9fc7330398846f67b5df7cdf3f33c3ca.png\n",
      "/kaggle/working/predicted_masks/2a365b5574868eb60861ee1ff0b8a4f6.png\n",
      "/kaggle/working/predicted_masks/936de314f2d95e6c487ffa651b477422.png\n",
      "/kaggle/working/predicted_masks/e5e8f14e1e0ae936de314f2d95e6c487.png\n",
      "/kaggle/working/predicted_masks/cb2eb1ef57af2ed9fbb63b28163a7459.png\n",
      "/kaggle/working/predicted_masks/7af2ed9fbb63b28163a745959c039830.png\n",
      "/kaggle/working/predicted_masks/0a5f3601ad4f13ccf1f4b331a412fc44.png\n",
      "/kaggle/working/predicted_masks/0a0317371a966bf4b3466463a3c64db1.png\n",
      "/kaggle/working/predicted_masks/7f0019f7e6af7d7147763bdfb928d788.png\n",
      "/kaggle/working/predicted_masks/3425b976973f13dd311a65d2b46d0a60.png\n",
      "/kaggle/working/predicted_masks/7f32574d6c748c41743c6c08a1d1ad8f.png\n",
      "/kaggle/working/predicted_masks/e1e0ae936de314f2d95e6c487ffa651b.png\n",
      "/kaggle/working/predicted_masks/0af3feff05dec1eb3a70b145a7d8d3b6.png\n",
      "/kaggle/working/predicted_masks/66e057db382b8564872a27301a654864.png\n",
      "/kaggle/working/predicted_masks/db5eb2a0e4b50889d874c68c030b9afe.png\n",
      "/kaggle/working/predicted_masks/5026b3550534bca540e24f489284b8e6.png\n",
      "/kaggle/working/predicted_masks/cbb2a365b5574868eb60861ee1ff0b8a.png\n",
      "/kaggle/working/predicted_masks/13dd311a65d2b46d0a6085835c525af6.png\n",
      "/kaggle/working/predicted_masks/f62f215f0da4ad3a7ab8df9da7386835.png\n",
      "/kaggle/working/predicted_masks/f8e26031fbb5e52c41545ba55aadaa77.png\n",
      "/kaggle/working/predicted_masks/3dd311a65d2b46d0a6085835c525af63.png\n",
      "/kaggle/working/predicted_masks/ff05dec1eb3a70b145a7d8d3b6c0ed75.png\n",
      "/kaggle/working/predicted_masks/3bbc04a3afe1f119f21b248d152b672a.png\n",
      "/kaggle/working/predicted_masks/27738677a6b1f2c6d40b3bbba8f6c704.png\n",
      "/kaggle/working/predicted_masks/1b62f15ec83b97bb11e8e0c4416c1931.png\n",
      "/kaggle/working/predicted_masks/6ad1468996b4a9ce6d840b53a6558038.png\n",
      "/kaggle/working/predicted_masks/d5060a633a8d5b2b2b55157b7781e2c7.png\n",
      "/kaggle/working/predicted_masks/71f2fd85a04faeeb2b535797395305af.png\n",
      "/kaggle/working/predicted_masks/a48847ae8395e56a6d9ba9d45c3dbc69.png\n",
      "/kaggle/working/predicted_masks/05734fbeedd0f9da760db74a29abdb04.png\n",
      "/kaggle/working/predicted_masks/87133b51209db6dcdda5cc8a788edaeb.png\n",
      "/kaggle/working/predicted_masks/3657e4314fe384eb2ba3adfda6c1899f.png\n",
      "/kaggle/working/predicted_masks/41ed86e58224cb76a67d4dcf9596154e.png\n",
      "/kaggle/working/predicted_masks/be4d18d5401f659532897255ce2dd4ae.png\n",
      "/kaggle/working/predicted_masks/4fda8daadc8dd23ae214d84b5dec33fd.png\n",
      "/kaggle/working/predicted_masks/1ad4f13ccf1f4b331a412fc44655fb51.png\n",
      "/kaggle/working/predicted_masks/f7fdb2d45b21960c94b0aab4c024a573.png\n",
      "/kaggle/working/predicted_masks/e8bfb905b78a91391adc0bb223c4eaf3.png\n",
      "/kaggle/working/predicted_masks/3f33c3ca4d5060a633a8d5b2b2b55157.png\n",
      "/kaggle/working/predicted_masks/67d4dcf9596154efb7cef748d9cbd617.png\n",
      "/kaggle/working/predicted_masks/9632a3c6f7f7fb2a643f15bd0249ddcc.png\n",
      "/kaggle/working/predicted_masks/94a7f32574d6c748c41743c6c08a1d1a.png\n",
      "/kaggle/working/predicted_masks/60b246359c68c836f843dcf41f4dce3c.png\n",
      "/kaggle/working/predicted_masks/8eb5a9a8a8d7fcc9df8e5ad89d284483.png\n",
      "/kaggle/working/predicted_masks/7ad1cf2eb9d32a3dc907950289e976c7.png\n",
      "/kaggle/working/predicted_masks/461c2a337948a41964c1d4f50a5f3601.png\n",
      "/kaggle/working/predicted_masks/eecd70ebce6347c491b37c8c2e5a64a8.png\n",
      "/kaggle/working/predicted_masks/633a8d5b2b2b55157b7781e2c706c75c.png\n",
      "/kaggle/working/predicted_masks/6f4d4987ea3b4bae5672a230194c5a08.png\n",
      "/kaggle/working/predicted_masks/39d6aad6bb0170a40ed32deef71fbe08.png\n",
      "/kaggle/working/predicted_masks/692195f853af7f8a4df1ec859759b7c8.png\n",
      "/kaggle/working/predicted_masks/1002ec4a1fe748f3085f1ce88cbdf366.png\n",
      "/kaggle/working/predicted_masks/dd78294679c9cbb2a365b5574868eb60.png\n",
      "/kaggle/working/predicted_masks/ff55177a34fc01019eec999fd84e679b.png\n",
      "/kaggle/working/predicted_masks/0fca6a4248a41e8db8b4ed633b456aaa.png\n",
      "/kaggle/working/predicted_masks/e73749a0d21db70dd094a7f32574d6c7.png\n",
      "/kaggle/working/predicted_masks/f14e1e0ae936de314f2d95e6c487ffa6.png\n",
      "/kaggle/working/predicted_masks/fdbc3bbc04a3afe1f119f21b248d152b.png\n",
      "/kaggle/working/predicted_masks/26679bff55177a34fc01019eec999fd8.png\n",
      "/kaggle/working/predicted_masks/50534bca540e24f489284b8e6953ad88.png\n",
      "/kaggle/working/predicted_masks/68d4b4ef4d95ceea11957998906d3694.png\n",
      "/kaggle/working/predicted_masks/391adc0bb223c4eaf3372eae567c94ea.png\n",
      "/kaggle/working/predicted_masks/8954bb13d3727c7e5e1069646f2f0bb8.png\n",
      "/kaggle/working/predicted_masks/a15fc656702fa602bb3c7abacdbd7e6a.png\n",
      "/kaggle/working/predicted_masks/1531871f2fd85a04faeeb2b535797395.png\n",
      "/kaggle/working/predicted_masks/7936140a2d5fc1443c4e445927738677.png\n",
      "/kaggle/working/predicted_masks/343f27ebc5d92b9076135d76d0bbd4ce.png\n",
      "/kaggle/working/predicted_masks/5c1346e62522325c1b9c4fc9cbe1eca1.png\n",
      "/kaggle/working/predicted_masks/dc0bb223c4eaf3372eae567c94ea04c6.png\n",
      "/kaggle/working/predicted_masks/80c643782707d7c359e27888daefee82.png\n",
      "/kaggle/working/predicted_masks/e1797c77826f9a7021bab9fc73303988.png\n",
      "/kaggle/working/predicted_masks/ad43fe2cd066b9fdbc3bbc04a3afe1f1.png\n",
      "/kaggle/working/predicted_masks/f13dd311a65d2b46d0a6085835c525af.png\n",
      "/kaggle/working/predicted_masks/782707d7c359e27888daefee82519763.png\n",
      "/kaggle/working/predicted_masks/cb1b387133b51209db6dcdda5cc8a788.png\n",
      "/kaggle/working/predicted_masks/4f437f0019f7e6af7d7147763bdfb928.png\n",
      "/kaggle/working/predicted_masks/4e2a6e51d077bad31c8c5f54ffaa27a6.png\n",
      "/kaggle/working/predicted_masks/aeeb2b535797395305af926a6f23c5d6.png\n",
      "/kaggle/working/predicted_masks/395e56a6d9ba9d45c3dbc695325ded46.png\n",
      "/kaggle/working/predicted_masks/c22268d4b4ef4d95ceea11957998906d.png\n",
      "/kaggle/working/predicted_masks/4c1711b62f15ec83b97bb11e8e0c4416.png\n",
      "/kaggle/working/predicted_masks/cdf3f33c3ca4d5060a633a8d5b2b2b55.png\n",
      "/kaggle/working/predicted_masks/7fda8019410b1fcf0625f608b4ce9762.png\n",
      "/kaggle/working/predicted_masks/8395e56a6d9ba9d45c3dbc695325ded4.png\n",
      "/kaggle/working/predicted_masks/e3c84417fda8019410b1fcf0625f608b.png\n",
      "/kaggle/working/predicted_masks/63b8318ecf467d7ad048df39beb17636.png\n",
      "/kaggle/working/predicted_masks/780fd497e1c0e9082ea2c193ac8d551c.png\n",
      "/kaggle/working/predicted_masks/559c7e610b1531871f2fd85a04faeeb2.png\n",
      "/kaggle/working/predicted_masks/39dda50f954ba59c7de13a35276a4764.png\n",
      "/kaggle/working/predicted_masks/0619ebebe9e9c9d00a4262b4fe4a5a95.png\n",
      "/kaggle/working/predicted_masks/a6e51d077bad31c8c5f54ffaa27a6235.png\n",
      "/kaggle/working/predicted_masks/626650908b1cb932a767bf5487ced51b.png\n",
      "/kaggle/working/predicted_masks/4417fda8019410b1fcf0625f608b4ce9.png\n",
      "/kaggle/working/predicted_masks/cf464aa36bf7c09a3bb0e5ca159410b9.png\n",
      "/kaggle/working/predicted_masks/019410b1fcf0625f608b4ce97629ab55.png\n",
      "/kaggle/working/predicted_masks/677a6b1f2c6d40b3bbba8f6c704801b3.png\n",
      "/kaggle/working/predicted_masks/cc5cfd263f1f90be28799235026b3550.png\n",
      "/kaggle/working/predicted_masks/df366e057db382b8564872a27301a654.png\n",
      "/kaggle/working/predicted_masks/a6d9ba9d45c3dbc695325ded465efde9.png\n",
      "/kaggle/working/predicted_masks/bec33b5e3d68f9d4c331587f9b9d49e2.png\n",
      "/kaggle/working/predicted_masks/7cb2eb1ef57af2ed9fbb63b28163a745.png\n",
      "/kaggle/working/predicted_masks/cf6644589e532a9ee954f81faedbce39.png\n",
      "/kaggle/working/predicted_masks/fb905b78a91391adc0bb223c4eaf3372.png\n",
      "/kaggle/working/predicted_masks/625559c7e610b1531871f2fd85a04fae.png\n",
      "/kaggle/working/predicted_masks/285e26c90e1797c77826f9a7021bab9f.png\n",
      "/kaggle/working/predicted_masks/30c2f4fc276ed9f178dc2f4af6266509.png\n",
      "/kaggle/working/predicted_masks/72d9e593b6be1ac29adbe86f03d900fd.png\n",
      "/kaggle/working/predicted_masks/be86f03d900fd197cd955fa095f97845.png\n",
      "/kaggle/working/predicted_masks/c7e610b1531871f2fd85a04faeeb2b53.png\n",
      "/kaggle/working/predicted_masks/6679bff55177a34fc01019eec999fd84.png\n",
      "/kaggle/working/predicted_masks/c5a0808bee60b246359c68c836f843dc.png\n",
      "/kaggle/working/predicted_masks/afe1f119f21b248d152b672ab3492fc6.png\n",
      "/kaggle/working/predicted_masks/4baddc22268d4b4ef4d95ceea1195799.png\n",
      "/kaggle/working/predicted_masks/e9082ea2c193ac8d551c149b60f29653.png\n",
      "/kaggle/working/predicted_masks/f8e5ad89d2844837f2a0f1536ad3f6a5.png\n",
      "/kaggle/working/predicted_masks/88e16d4ca6160127cd1d5ff99c267599.png\n",
      "/kaggle/working/predicted_masks/c4be73749a0d21db70dd094a7f32574d.png\n",
      "/kaggle/working/predicted_masks/98da48d679d7c7c8d3d96fb2b87fbbcf.png\n",
      "/kaggle/working/predicted_masks/d694539ef2424a9218697283baa3657e.png\n",
      "/kaggle/working/predicted_masks/15fc656702fa602bb3c7abacdbd7e6af.png\n",
      "/kaggle/working/predicted_masks/a6a4248a41e8db8b4ed633b456aaafac.png\n",
      "/kaggle/working/predicted_masks/a3657e4314fe384eb2ba3adfda6c1899.png\n",
      "/kaggle/working/predicted_masks/05b78a91391adc0bb223c4eaf3372eae.png\n",
      "/kaggle/working/predicted_masks/45b21960c94b0aab4c024a573c692195.png\n",
      "/kaggle/working/predicted_masks/77e004e8bfb905b78a91391adc0bb223.png\n",
      "/kaggle/working/predicted_masks/2cd066b9fdbc3bbc04a3afe1f119f21b.png\n",
      "/kaggle/working/predicted_masks/eff05dec1eb3a70b145a7d8d3b6c0ed7.png\n",
      "/kaggle/working/predicted_masks/faef7fdb2d45b21960c94b0aab4c024a.png\n",
      "/kaggle/working/predicted_masks/d3694abb47953b0e4909384b57bb6a05.png\n",
      "/kaggle/working/predicted_masks/6ddca6ee1af35b65bd9ea42cfcfedb5e.png\n",
      "/kaggle/working/predicted_masks/710d568df17586ad8f3297c819c90895.png\n",
      "/kaggle/working/predicted_masks/6d3694abb47953b0e4909384b57bb6a0.png\n",
      "/kaggle/working/predicted_masks/a9d45c3dbc695325ded465efde988dfb.png\n",
      "/kaggle/working/predicted_masks/3c692195f853af7f8a4df1ec859759b7.png\n",
      "/kaggle/working/predicted_masks/a51625559c7e610b1531871f2fd85a04.png\n",
      "/kaggle/working/predicted_masks/7b5df7cdf3f33c3ca4d5060a633a8d5b.png\n",
      "/kaggle/working/predicted_masks/60a633a8d5b2b2b55157b7781e2c706c.png\n",
      "/kaggle/working/predicted_masks/0398846f67b5df7cdf3f33c3ca4d5060.png\n",
      "/kaggle/working/predicted_masks/dc70626ab4ec3d46e602b296cc5cfd26.png\n",
      "/kaggle/working/predicted_masks/ea42b4eebc9e5a87e443434ac60af150.png\n",
      "/kaggle/working/predicted_masks/3b8318ecf467d7ad048df39beb176363.png\n",
      "/kaggle/working/predicted_masks/c41545ba55aadaa77712a48e11d579d9.png\n",
      "/kaggle/working/predicted_masks/e19769fa2d37d32780fd497e1c0e9082.png\n",
      "/kaggle/working/predicted_masks/d6240619ebebe9e9c9d00a4262b4fe4a.png\n",
      "/kaggle/working/predicted_masks/6f67b5df7cdf3f33c3ca4d5060a633a8.png\n",
      "/kaggle/working/predicted_masks/1209db6dcdda5cc8a788edaeb6aa460a.png\n",
      "/kaggle/working/predicted_masks/1c0e9082ea2c193ac8d551c149b60f29.png\n",
      "/kaggle/working/predicted_masks/e4a17af18f72c8e6166a915669c99390.png\n",
      "/kaggle/working/predicted_masks/dd094a7f32574d6c748c41743c6c08a1.png\n",
      "/kaggle/working/predicted_masks/e7998934d417cb2eb1ef57af2ed9fbb6.png\n",
      "/kaggle/working/predicted_masks/425b976973f13dd311a65d2b46d0a608.png\n",
      "/kaggle/working/predicted_masks/54ba59c7de13a35276a476420655433a.png\n",
      "/kaggle/working/predicted_masks/4ca6160127cd1d5ff99c267599fc487b.png\n",
      "/kaggle/working/predicted_masks/268d4b4ef4d95ceea11957998906d369.png\n",
      "/kaggle/working/predicted_masks/3c84417fda8019410b1fcf0625f608b4.png\n",
      "/kaggle/working/predicted_masks/5664c1711b62f15ec83b97bb11e8e0c4.png\n",
      "/kaggle/working/predicted_masks/7cdf3f33c3ca4d5060a633a8d5b2b2b5.png\n",
      "/kaggle/working/predicted_masks/4ef4d95ceea11957998906d3694abb47.png\n",
      "/kaggle/working/predicted_masks/9c7976c1182df0de51d32128c358d1fd.png\n",
      "/kaggle/working/predicted_masks/ca4d5060a633a8d5b2b2b55157b7781e.png\n",
      "/kaggle/working/predicted_masks/7330398846f67b5df7cdf3f33c3ca4d5.png\n",
      "/kaggle/working/predicted_masks/8cbdf366e057db382b8564872a27301a.png\n",
      "/kaggle/working/predicted_masks/b21960c94b0aab4c024a573c692195f8.png\n",
      "/kaggle/working/predicted_masks/314fe384eb2ba3adfda6c1899fdc9837.png\n",
      "/kaggle/working/predicted_masks/6240619ebebe9e9c9d00a4262b4fe4a5.png\n",
      "/kaggle/working/predicted_masks/6231002ec4a1fe748f3085f1ce88cbdf.png\n",
      "/kaggle/working/predicted_masks/6b83ef461c2a337948a41964c1d4f50a.png\n",
      "/kaggle/working/predicted_masks/aafac813fe3ccba3e032dd2948a80c64.png\n",
      "/kaggle/working/predicted_masks/5b21960c94b0aab4c024a573c692195f.png\n",
      "/kaggle/working/predicted_masks/1db239dda50f954ba59c7de13a35276a.png\n",
      "/kaggle/working/predicted_masks/82ea2c193ac8d551c149b60f2965341c.png\n",
      "/kaggle/working/predicted_masks/d077bad31c8c5f54ffaa27a623511c38.png\n",
      "/kaggle/working/predicted_masks/85a04faeeb2b535797395305af926a6f.png\n",
      "/kaggle/working/predicted_masks/318ecf467d7ad048df39beb176363408.png\n",
      "/kaggle/working/predicted_masks/5beb48f0be11d0309d1dff09b8405734.png\n",
      "/kaggle/working/predicted_masks/80cae6daedd989517cb8041ed86e5822.png\n",
      "/kaggle/working/predicted_masks/c695325ded465efde988dfb96d081533.png\n",
      "/kaggle/working/predicted_masks/fcd6da15fc656702fa602bb3c7abacdb.png\n",
      "/kaggle/working/predicted_masks/02fa602bb3c7abacdbd7e6afd56ea7bc.png\n",
      "/kaggle/working/predicted_masks/af35b65bd9ea42cfcfedb5eb2a0e4b50.png\n",
      "/kaggle/working/predicted_masks/8b8ec74baddc22268d4b4ef4d95ceea1.png\n",
      "/kaggle/working/predicted_masks/df8e26031fbb5e52c41545ba55aadaa7.png\n",
      "/kaggle/working/predicted_masks/5a51625559c7e610b1531871f2fd85a0.png\n",
      "/kaggle/working/predicted_masks/c193ac8d551c149b60f2965341caf528.png\n"
     ]
    }
   ],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 0] = 255\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    \n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def mask2string(dir):\n",
    "    ## mask --> string\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/predicted_masks'\n",
    "MASK_DIR_PATH = '/test_gt/test_gt/'\n",
    "res = mask2string(MASK_DIR_PATH)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
